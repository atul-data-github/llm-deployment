{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96958124-182d-45c6-a56f-f4ab8d0dfd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 10 05:57:13 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4500               On  | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              13W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4500               On  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 30%   40C    P8              15W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ae795c-e4ad-4ec6-b5e8-3658c45ed2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2637b973-ce58-4c51-8c22-e64f0d31754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df263263-347b-4ad3-8b61-bd841cce3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae678c8-1a0e-40f1-9449-33916d9eab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4132/3640145678.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 02-10 05:57:25 config.py:549] Casting torch.bfloat16 to torch.float16.\n",
      "WARNING 02-10 05:57:25 config.py:177] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 02-10 05:57:25 llm_engine.py:72] Initializing an LLM engine with config: model='TheBloke/Mistral-7B-v0.1-AWQ', tokenizer='TheBloke/Mistral-7B-v0.1-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir='/workspace/', load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, seed=0)\n",
      "INFO 02-10 05:57:28 weight_utils.py:164] Using model weights format ['*.safetensors']\n",
      "INFO 02-10 05:57:53 llm_engine.py:322] # GPU blocks: 5544, # CPU blocks: 2048\n",
      "INFO 02-10 05:57:55 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-10 05:57:55 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-10 05:58:01 model_runner.py:698] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "#from prompts import questions\n",
    "#from rich.progress import track\n",
    "tensor_parallel_size = int(os.environ.get(\"DEVICES\", \"1\"))\n",
    "\n",
    "llm = LLM(\n",
    "    \"TheBloke/Mistral-7B-v0.1-AWQ\",\n",
    "    dtype=torch.float16,\n",
    "    quantization=\"AWQ\",\n",
    "    tensor_parallel_size=tensor_parallel_size,\n",
    "    gpu_memory_utilization=0.8,\n",
    "    max_model_len=4096,\n",
    "    download_dir=\"/workspace/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd680a50-7787-448f-bc1b-df14e452bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afff3874-b3ad-4def-8f13-4ee66b82ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "out = llm.generate(\"This is me warming up the model\", sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6999c419-4b9d-47e3-bcfc-f213d4a51010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\", I took some quite decent pictures of the model for one of my flight simulations a while back, so I started putting them together into a cute little thing (and title sequence...?)\\n\\nIf anyone has heard of or is even a part of the VTOL/SIM1000SANE area, you can use me as proof that not all the models/creations are much use and that you can be better than the rest of us.\\n\\nAnyway, a few comments:\\n\\n1) I have no idea how to contain the title screen within a single file, so go figure.\\n\\n2) My VCR was kinda acting up (see the blue and purple visual)\\n\\n3) My computer wasn't reacting very well because it seems like it wants an NTSC professor to Fren anim and I'm using NTSC. Obviously I don't know about video signals so if you're a little smarter than me\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out[0].prompt,\n",
    "out[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63c9b28-049d-4d1e-9fcc-49d0ce4dc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inference through 100 prompt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:32,  2.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:04<03:28,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:05<03:06,  1.93s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:08<03:12,  2.00s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:10<03:14,  2.04s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:12<03:14,  2.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:14<03:13,  2.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:16<03:12,  2.10s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:18<02:57,  1.95s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:20<03:00,  2.00s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:21<02:48,  1.90s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:24<02:53,  1.97s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:26<02:55,  2.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:27<02:43,  1.90s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:29<02:47,  1.97s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:32<02:49,  2.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:34<02:50,  2.05s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:36<02:50,  2.08s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:38<02:49,  2.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 20%|██        | 20/100 [00:40<02:48,  2.11s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\u001b[A\n",
      " 21%|██        | 21/100 [00:42<02:32,  1.94s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:44<02:35,  2.00s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:46<02:37,  2.04s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:48<02:37,  2.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:50<02:36,  2.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:52<02:25,  1.96s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:53<02:13,  1.82s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:55<02:03,  1.71s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:57<02:10,  1.84s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\u001b[A\n",
      " 30%|███       | 30/100 [00:58<02:01,  1.73s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:01<02:08,  1.86s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:03<02:12,  1.94s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:05<02:14,  2.01s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:06<02:03,  1.87s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:08<02:02,  1.88s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:11<02:05,  1.96s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:13<02:07,  2.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [01:14<01:58,  1.91s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [01:16<02:00,  1.98s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 40%|████      | 40/100 [01:19<02:02,  2.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 41%|████      | 41/100 [01:21<02:01,  2.06s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [01:23<02:01,  2.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [01:25<02:00,  2.11s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [01:27<01:59,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [01:29<01:57,  2.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [01:31<01:45,  1.96s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [01:33<01:47,  2.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [01:35<01:47,  2.06s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [01:37<01:46,  2.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [01:40<01:45,  2.11s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [01:42<01:44,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [01:44<01:42,  2.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [01:46<01:40,  2.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [01:48<01:39,  2.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [01:50<01:37,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [01:53<01:34,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [01:55<01:32,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [01:57<01:30,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [01:59<01:28,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [02:01<01:26,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [02:03<01:24,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [02:05<01:16,  2.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [02:07<01:16,  2.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [02:09<01:11,  1.98s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [02:11<01:11,  2.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [02:13<01:10,  2.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [02:16<01:09,  2.10s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [02:18<01:07,  2.12s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [02:20<01:06,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [02:22<01:04,  2.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [02:24<01:02,  2.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [02:26<01:00,  2.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [02:29<00:58,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [02:31<00:56,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [02:33<00:54,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [02:35<00:51,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [02:37<00:49,  2.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [02:39<00:47,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [02:42<00:45,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [02:44<00:43,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [02:46<00:41,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [02:48<00:39,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [02:50<00:36,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [02:52<00:34,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [02:55<00:32,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [02:57<00:30,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [02:59<00:28,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [03:01<00:25,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [03:03<00:23,  2.17s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [03:05<00:20,  2.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [03:07<00:18,  2.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [03:09<00:16,  2.10s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [03:11<00:14,  2.12s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [03:14<00:12,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [03:16<00:10,  2.13s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [03:18<00:08,  2.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.82it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [03:18<00:04,  1.58s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [03:20<00:03,  1.76s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [03:22<00:01,  1.73s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      "100%|██████████| 100/100 [03:24<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens/sec:  92.864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "questions = [\"This is me warming up the model\"]*100\n",
    "\n",
    "\n",
    "print(f\"running inference through {len(questions)} prompt.\")\n",
    "\n",
    "results = []\n",
    "for q in tqdm.tqdm(questions):\n",
    "    t0 = time.perf_counter()\n",
    "    output = llm.generate(q, sampling_params=sampling_params)[0]\n",
    "    t1 = time.perf_counter()\n",
    "    results.append(\n",
    "        {\"time\": t1 - t0, \"tokens_generated\": len(output.outputs[0].token_ids)}\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df[\"tokens_per_sec\"] = df.tokens_generated / df.time\n",
    "print(f\"Average tokens/sec: {df.tokens_per_sec.mean(): .3f}\")\n",
    "df.to_csv(f\"vllm-benchmark-{tensor_parallel_size}GPUs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e93070e-42d3-4c94-b41e-facb9e8b1998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tokens_generated</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.141536</td>\n",
       "      <td>200</td>\n",
       "      <td>93.390914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.125399</td>\n",
       "      <td>200</td>\n",
       "      <td>94.099979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.678761</td>\n",
       "      <td>158</td>\n",
       "      <td>94.117004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.123570</td>\n",
       "      <td>200</td>\n",
       "      <td>94.181032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.116070</td>\n",
       "      <td>200</td>\n",
       "      <td>94.514810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.166045</td>\n",
       "      <td>200</td>\n",
       "      <td>92.334199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.266486</td>\n",
       "      <td>24</td>\n",
       "      <td>90.060928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.166427</td>\n",
       "      <td>200</td>\n",
       "      <td>92.317923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.667261</td>\n",
       "      <td>154</td>\n",
       "      <td>92.367061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.165785</td>\n",
       "      <td>200</td>\n",
       "      <td>92.345254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  tokens_generated  tokens_per_sec\n",
       "0   2.141536               200       93.390914\n",
       "1   2.125399               200       94.099979\n",
       "2   1.678761               158       94.117004\n",
       "3   2.123570               200       94.181032\n",
       "4   2.116070               200       94.514810\n",
       "..       ...               ...             ...\n",
       "95  2.166045               200       92.334199\n",
       "96  0.266486                24       90.060928\n",
       "97  2.166427               200       92.317923\n",
       "98  1.667261               154       92.367061\n",
       "99  2.165785               200       92.345254\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7715c2-5054-4241-a116-794625997846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_parallel_size = 1\n",
    "df.to_csv(f\"vllm-benchmark-{tensor_parallel_size}GPUs AWQ.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42dd63c-8928-4c06-9297-ec0a51ab4c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
