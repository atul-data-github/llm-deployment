{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96958124-182d-45c6-a56f-f4ab8d0dfd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 10 05:33:38 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A4500               On  | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   26C    P8              14W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A4500               On  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 30%   30C    P8              14W / 200W |      2MiB / 20470MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ae795c-e4ad-4ec6-b5e8-3658c45ed2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.6)\n",
      "Collecting ray>=2.9 (from vllm)\n",
      "  Downloading ray-2.9.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.24.1)\n",
      "Collecting torch==2.1.2 (from vllm)\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting transformers>=4.37.0 (from vllm)\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xformers==0.0.23.post1 (from vllm)\n",
      "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting fastapi (from vllm)\n",
      "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn[standard] (from vllm)\n",
      "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pydantic>=2.0 (from vllm)\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aioprometheus[starlette] (from vllm)\n",
      "  Downloading aioprometheus-23.12.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pynvml==11.5.0 (from vllm)\n",
      "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2.1.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->vllm)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic>=2.0->vllm)\n",
      "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions (from torch==2.1.2->vllm)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click>=7.0 (from ray>=2.9->vllm)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (4.19.2)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray>=2.9->vllm)\n",
      "  Downloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (23.2)\n",
      "Collecting protobuf!=3.19.5,>=3.15.3 (from ray>=2.9->vllm)\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (6.0.1)\n",
      "Collecting aiosignal (from ray>=2.9->vllm)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist (from ray>=2.9->vllm)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (2.31.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers>=4.37.0->vllm)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.37.0->vllm)\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers>=4.37.0->vllm)\n",
      "  Downloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.37.0->vllm)\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers>=4.37.0->vllm)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson (from aioprometheus[starlette]->vllm)\n",
      "  Downloading orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm)\n",
      "  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting starlette>=0.14.2 (from aioprometheus[starlette]->vllm)\n",
      "  Downloading starlette-0.37.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting fsspec (from torch==2.1.2->vllm)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.14.2->aioprometheus[starlette]->vllm) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->vllm) (2.1.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.1.3)\n",
      "Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.9.2-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (530 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m530.8/530.8 kB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m135.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: quantile-python\n",
      "  Building wheel for quantile-python (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3443 sha256=a3b220ee66d3cc15bb6c0a4676588c1c7e83945fc3c80dd2520ed9a3d9a3e9aa\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n",
      "Successfully built quantile-python\n",
      "Installing collected packages: sentencepiece, quantile-python, ninja, websockets, uvloop, typing-extensions, tqdm, safetensors, regex, python-dotenv, pynvml, protobuf, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgpack, httptools, h11, fsspec, frozenlist, click, annotated-types, watchfiles, uvicorn, starlette, pydantic-core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, aiosignal, aioprometheus, tokenizers, pydantic, nvidia-cusolver-cu12, transformers, torch, ray, fastapi, xformers, vllm\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aioprometheus-23.12.0 aiosignal-1.3.1 annotated-types-0.6.0 click-8.1.7 fastapi-0.109.2 frozenlist-1.4.1 fsspec-2024.2.0 h11-0.14.0 httptools-0.6.1 huggingface-hub-0.20.3 msgpack-1.0.7 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 orjson-3.9.13 protobuf-4.25.2 pydantic-2.6.1 pydantic-core-2.16.2 pynvml-11.5.0 python-dotenv-1.0.1 quantile-python-1.1 ray-2.9.2 regex-2023.12.25 safetensors-0.4.2 sentencepiece-0.1.99 starlette-0.36.3 tokenizers-0.15.1 torch-2.1.2 tqdm-4.66.1 transformers-4.37.2 typing-extensions-4.9.0 uvicorn-0.27.0.post1 uvloop-0.19.0 vllm-0.3.0 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2637b973-ce58-4c51-8c22-e64f0d31754d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.0 pytz-2024.1 tzdata-2023.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df263263-347b-4ad3-8b61-bd841cce3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae678c8-1a0e-40f1-9449-33916d9eab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137/874639394.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad287362af54b0b815d7dfa1904aa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 05:35:47,524\tWARNING utils.py:575 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.\n",
      "2024-02-10 05:35:47,526\tWARNING utils.py:587 -- Ray currently does not support initializing Ray with fractional cpus. Your num_cpus will be truncated from 20.4 to 20.\n",
      "2024-02-10 05:35:47,677\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-10 05:35:48 llm_engine.py:72] Initializing an LLM engine with config: model='mistralai/Mistral-7B-v0.1', tokenizer='mistralai/Mistral-7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir='/workspace/', load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, seed=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55785ad79bcd451ba223476ffef6edcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2746c6072248c38881ec544aeebd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af56618d762f4a2a8103d4b76b804d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfecb7f9220a413f980a464043a23908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-10 05:35:59 weight_utils.py:164] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(RayWorkerVllm pid=1712)\u001b[0m INFO 02-10 05:35:59 weight_utils.py:164] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5076e14394b345c1b96235b28612235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9665e6fa5b2d4a12ac572a5e06122fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 02-10 05:37:48 llm_engine.py:322] # GPU blocks: 8214, # CPU blocks: 4096\n",
      "INFO 02-10 05:37:50 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 02-10 05:37:50 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "\u001b[36m(RayWorkerVllm pid=1712)\u001b[0m INFO 02-10 05:37:50 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[36m(RayWorkerVllm pid=1712)\u001b[0m INFO 02-10 05:37:50 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 02-10 05:37:55 custom_all_reduce.py:199] Registering 2275 cuda graph addresses\n",
      "INFO 02-10 05:37:55 model_runner.py:698] Graph capturing finished in 5 secs.\n",
      "\u001b[36m(RayWorkerVllm pid=1712)\u001b[0m INFO 02-10 05:37:55 custom_all_reduce.py:199] Registering 2275 cuda graph addresses\n",
      "\u001b[36m(RayWorkerVllm pid=1712)\u001b[0m INFO 02-10 05:37:55 model_runner.py:698] Graph capturing finished in 5 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import torch\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import tqdm\n",
    "#from prompts import questions\n",
    "#from rich.progress import track\n",
    "\n",
    "tensor_parallel_size = int(os.environ.get(\"DEVICES\", \"2\"))\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=200)\n",
    "\n",
    "llm = LLM(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    tensor_parallel_size=tensor_parallel_size,\n",
    "    dtype=torch.bfloat16,\n",
    "    gpu_memory_utilization=0.8,\n",
    "    max_model_len=4096,\n",
    "    download_dir=\"/workspace/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afff3874-b3ad-4def-8f13-4ee66b82ed1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    }
   ],
   "source": [
    "out = llm.generate(\"This is me warming up the model\", sampling_params=sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6999c419-4b9d-47e3-bcfc-f213d4a51010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', I took some quite fun pictures of this, for one I was trying to see the etch-a-Sketch and draw on the screen! (Horrible, so messy) but I also did a bit of graffiti style bombing. Obviously none of this worked as the model isn’t real. But I watched a programme yesterday about the coming Arctic melt down (Which coincidently is what I wrote my final essay on at university), and we’re a serious mess. If the world´s largest reservoir of methane – the large reserves of frozen underwater methane – is released, It would be the end of the world.\\n\\nI say in a drawing 🙂 It defiantly would be a bright place to be!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out[0].prompt,\n",
    "out[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e63c9b28-049d-4d1e-9fcc-49d0ce4dc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running inference through 100 prompt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      "  1%|          | 1/100 [00:03<05:41,  3.45s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\u001b[A\n",
      "  2%|▏         | 2/100 [00:06<04:54,  3.01s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      "  3%|▎         | 3/100 [00:09<05:09,  3.19s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      "  4%|▍         | 4/100 [00:12<05:14,  3.28s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\u001b[A\n",
      "  5%|▌         | 5/100 [00:16<05:14,  3.31s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      "  6%|▌         | 6/100 [00:19<05:14,  3.34s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\u001b[A\n",
      "  7%|▋         | 7/100 [00:22<04:41,  3.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      "  8%|▊         | 8/100 [00:25<04:49,  3.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\u001b[A\n",
      "  9%|▉         | 9/100 [00:28<04:53,  3.22s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\u001b[A\n",
      " 10%|█         | 10/100 [00:32<04:54,  3.27s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 11%|█         | 11/100 [00:35<04:55,  3.32s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:39<04:54,  3.35s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:42<04:52,  3.36s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:45<04:50,  3.38s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:49<04:48,  3.39s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:52<04:45,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:56<04:42,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:59<04:37,  3.39s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 19%|█▉        | 19/100 [01:02<04:35,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 20%|██        | 20/100 [01:06<04:32,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\u001b[A\n",
      " 21%|██        | 21/100 [01:09<04:13,  3.21s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\u001b[A\n",
      " 22%|██▏       | 22/100 [01:12<04:14,  3.27s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 23%|██▎       | 23/100 [01:15<04:14,  3.31s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\u001b[A\n",
      " 24%|██▍       | 24/100 [01:18<03:50,  3.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\u001b[A\n",
      " 25%|██▌       | 25/100 [01:20<03:34,  2.85s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it]\u001b[A\n",
      " 26%|██▌       | 26/100 [01:23<03:35,  2.92s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 27%|██▋       | 27/100 [01:27<03:43,  3.06s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\u001b[A\n",
      " 28%|██▊       | 28/100 [01:30<03:35,  2.99s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\u001b[A\n",
      " 29%|██▉       | 29/100 [01:32<03:18,  2.80s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\u001b[A\n",
      " 30%|███       | 30/100 [01:35<03:27,  2.97s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\u001b[A\n",
      " 31%|███       | 31/100 [01:39<03:33,  3.09s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 32%|███▏      | 32/100 [01:42<03:37,  3.19s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\u001b[A\n",
      " 33%|███▎      | 33/100 [01:45<03:35,  3.22s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\u001b[A\n",
      " 34%|███▍      | 34/100 [01:48<03:11,  2.90s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\u001b[A\n",
      " 35%|███▌      | 35/100 [01:51<03:19,  3.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 36%|███▌      | 36/100 [01:54<03:23,  3.18s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 37%|███▋      | 37/100 [01:58<03:25,  3.26s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 38%|███▊      | 38/100 [02:01<03:25,  3.31s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\u001b[A\n",
      " 39%|███▉      | 39/100 [02:05<03:24,  3.36s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\u001b[A\n",
      " 40%|████      | 40/100 [02:08<03:13,  3.23s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 41%|████      | 41/100 [02:11<03:14,  3.29s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 42%|████▏     | 42/100 [02:15<03:13,  3.34s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 43%|████▎     | 43/100 [02:18<03:11,  3.37s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 44%|████▍     | 44/100 [02:21<03:09,  3.39s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\u001b[A\n",
      " 45%|████▌     | 45/100 [02:25<03:00,  3.29s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\u001b[A\n",
      " 46%|████▌     | 46/100 [02:28<02:59,  3.32s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\u001b[A\n",
      " 47%|████▋     | 47/100 [02:31<02:57,  3.34s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 48%|████▊     | 48/100 [02:35<02:54,  3.36s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\u001b[A\n",
      " 49%|████▉     | 49/100 [02:37<02:42,  3.18s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 50%|█████     | 50/100 [02:41<02:42,  3.25s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\u001b[A\n",
      " 51%|█████     | 51/100 [02:43<02:29,  3.05s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 52%|█████▏    | 52/100 [02:47<02:31,  3.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\u001b[A\n",
      " 53%|█████▎    | 53/100 [02:49<02:16,  2.91s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 54%|█████▍    | 54/100 [02:53<02:21,  3.07s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\u001b[A\n",
      " 55%|█████▌    | 55/100 [02:55<02:07,  2.84s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 56%|█████▌    | 56/100 [02:58<02:12,  3.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 57%|█████▋    | 57/100 [03:02<02:15,  3.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 58%|█████▊    | 58/100 [03:05<02:15,  3.23s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 59%|█████▉    | 59/100 [03:09<02:14,  3.29s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      " 60%|██████    | 60/100 [03:11<02:05,  3.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 61%|██████    | 61/100 [03:15<02:05,  3.22s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 62%|██████▏   | 62/100 [03:18<02:04,  3.29s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\u001b[A\n",
      " 63%|██████▎   | 63/100 [03:21<01:56,  3.16s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\u001b[A\n",
      " 64%|██████▍   | 64/100 [03:23<01:42,  2.85s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 65%|██████▌   | 65/100 [03:27<01:45,  3.02s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 66%|██████▌   | 66/100 [03:30<01:46,  3.14s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\u001b[A\n",
      " 67%|██████▋   | 67/100 [03:33<01:40,  3.04s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\u001b[A\n",
      " 68%|██████▊   | 68/100 [03:36<01:40,  3.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\u001b[A\n",
      " 69%|██████▉   | 69/100 [03:40<01:39,  3.20s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 70%|███████   | 70/100 [03:43<01:38,  3.27s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 71%|███████   | 71/100 [03:47<01:36,  3.32s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 72%|███████▏  | 72/100 [03:50<01:33,  3.36s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 73%|███████▎  | 73/100 [03:53<01:31,  3.38s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 74%|███████▍  | 74/100 [03:57<01:28,  3.39s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 75%|███████▌  | 75/100 [04:00<01:24,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 76%|███████▌  | 76/100 [04:04<01:21,  3.41s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\u001b[A\n",
      " 77%|███████▋  | 77/100 [04:06<01:13,  3.19s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 78%|███████▊  | 78/100 [04:10<01:11,  3.26s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\u001b[A\n",
      " 79%|███████▉  | 79/100 [04:13<01:09,  3.30s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\u001b[A\n",
      " 80%|████████  | 80/100 [04:16<01:00,  3.03s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 81%|████████  | 81/100 [04:19<00:59,  3.15s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 82%|████████▏ | 82/100 [04:22<00:58,  3.23s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\u001b[A\n",
      " 83%|████████▎ | 83/100 [04:26<00:56,  3.30s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 84%|████████▍ | 84/100 [04:29<00:53,  3.34s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      " 85%|████████▌ | 85/100 [04:33<00:50,  3.37s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\u001b[A\n",
      " 86%|████████▌ | 86/100 [04:36<00:46,  3.31s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\u001b[A\n",
      " 87%|████████▋ | 87/100 [04:39<00:41,  3.22s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 88%|████████▊ | 88/100 [04:42<00:39,  3.28s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 89%|████████▉ | 89/100 [04:46<00:36,  3.33s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 90%|█████████ | 90/100 [04:49<00:33,  3.36s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 91%|█████████ | 91/100 [04:53<00:30,  3.38s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 92%|█████████▏| 92/100 [04:56<00:27,  3.39s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\u001b[A\n",
      " 93%|█████████▎| 93/100 [05:00<00:23,  3.40s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 94%|█████████▍| 94/100 [05:03<00:20,  3.41s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\u001b[A\n",
      " 95%|█████████▌| 95/100 [05:06<00:16,  3.30s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 96%|█████████▌| 96/100 [05:09<00:13,  3.34s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\u001b[A\n",
      " 97%|█████████▋| 97/100 [05:12<00:08,  2.98s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\u001b[A\n",
      " 98%|█████████▊| 98/100 [05:15<00:06,  3.12s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\u001b[A\n",
      " 99%|█████████▉| 99/100 [05:18<00:03,  3.21s/it]\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\u001b[A\n",
      "100%|██████████| 100/100 [05:22<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens/sec:  58.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "questions = [\"This is me warming up the model\"]*100\n",
    "\n",
    "\n",
    "print(f\"running inference through {len(questions)} prompt.\")\n",
    "\n",
    "results = []\n",
    "for q in tqdm.tqdm(questions):\n",
    "    t0 = time.perf_counter()\n",
    "    output = llm.generate(q, sampling_params=sampling_params)[0]\n",
    "    t1 = time.perf_counter()\n",
    "    results.append(\n",
    "        {\"time\": t1 - t0, \"tokens_generated\": len(output.outputs[0].token_ids)}\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df[\"tokens_per_sec\"] = df.tokens_generated / df.time\n",
    "print(f\"Average tokens/sec: {df.tokens_per_sec.mean(): .3f}\")\n",
    "df.to_csv(f\"vllm-benchmark-{tensor_parallel_size}GPUs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93070e-42d3-4c94-b41e-facb9e8b1998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tokens_generated</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.467020</td>\n",
       "      <td>200</td>\n",
       "      <td>30.926143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.482062</td>\n",
       "      <td>200</td>\n",
       "      <td>30.854381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.468573</td>\n",
       "      <td>200</td>\n",
       "      <td>30.918723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.520680</td>\n",
       "      <td>200</td>\n",
       "      <td>30.671649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.506878</td>\n",
       "      <td>200</td>\n",
       "      <td>30.736706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6.466887</td>\n",
       "      <td>200</td>\n",
       "      <td>30.926780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.454921</td>\n",
       "      <td>200</td>\n",
       "      <td>30.984114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.455175</td>\n",
       "      <td>200</td>\n",
       "      <td>30.982892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.163166</td>\n",
       "      <td>191</td>\n",
       "      <td>30.990566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6.456795</td>\n",
       "      <td>200</td>\n",
       "      <td>30.975121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  tokens_generated  tokens_per_sec\n",
       "0   6.467020               200       30.926143\n",
       "1   6.482062               200       30.854381\n",
       "2   6.468573               200       30.918723\n",
       "3   6.520680               200       30.671649\n",
       "4   6.506878               200       30.736706\n",
       "..       ...               ...             ...\n",
       "95  6.466887               200       30.926780\n",
       "96  6.454921               200       30.984114\n",
       "97  6.455175               200       30.982892\n",
       "98  6.163166               191       30.990566\n",
       "99  6.456795               200       30.975121\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
